{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningML8Resampling.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akif-Mufti/Machine-Learning-with-Python/blob/master/LearningML8Resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFkDtUkuB0Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c187670a-999e-4f07-8ed2-c4e080c8229b"
      },
      "source": [
        "# You need to know how well your algorithms perform on unseen data. The best way to evaluate\n",
        "# the performance of an algorithm would be to make predictions for new data to which you\n",
        "# already know the answers. The second best way is to use clever techniques from statistics called\n",
        "# resampling methods that allow you to make accurate estimates for how well your algorithm will\n",
        "# perform on new data.\n",
        "\n",
        "#training/Testing split = 67/33%\n",
        "\n",
        "# Evaluate using a train and a test set\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result*100.0))\n",
        "\n",
        "\n",
        "# Note that\n",
        "# in addition to specifying the size of the split, we also specify the random seed. Because the\n",
        "# split of the data is random, we want to ensure that the results are reproducible. By specifying\n",
        "# the random seed we ensure that we get the same random numbers each time we run the code\n",
        "# and in turn the same split of data."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 75.591%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}