{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bagging1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akif-Mufti/Machine-Learning-with-Python/blob/master/Bagging1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OElezXhkHQuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Bagging. Building multiple models (typically of the same type) from di\u000berent subsamples\n",
        "# of the training dataset.\n",
        "#  Boosting. Building multiple models (typically of the same type) each of which learns to\n",
        "# \fx the prediction errors of a prior model in the sequence of models.\n",
        "#  Voting. Building multiple models (typically of di\u000bering types) and simple statistics (like\n",
        "# calculating the mean) are used to combine predictions."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtxuEqzgHTN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bootstrap Aggregation (or Bagging) involves taking multiple samples from your training dataset\n",
        "# (with replacement) and training a model for each sample. The \fnal output prediction is averaged\n",
        "# across the predictions of all of the sub-models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l_Q57g9HlO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bagged Decision Trees\n",
        "# Bagging performs best with algorithms that have high variance. A popular example are\n",
        "# decision trees, often constructed without pruning. In the example below is an example\n",
        "# of using the BaggingClassifier with the Classi\fcation and Regression Trees algorithm\n",
        "# (DecisionTreeClassifier1). A total of 100 trees are created."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmb07NkSHz5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb9d2c09-1812-4b96-e0d0-183485474f75"
      },
      "source": [
        "# Bagged Decision Trees for Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=10, random_state=seed)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.770745044429255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFLXj5CIIAqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forests is an extension of bagged decision trees. Samples of the training dataset are\n",
        "# taken with replacement, but the trees are constructed in a way that reduces the correlation\n",
        "# between individual classi\fers. Speci\fcally, rather than greedily choosing the best split point in\n",
        "# the construction of each tree, only a random subset of features are considered for each split."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc6jer-NICOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4daede80-ca22-48b6-aeb6-bc0cf7e3ec99"
      },
      "source": [
        "# Random Forest Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7695146958304853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWlp7xjKIGyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extra Trees are another modi\fcation of bagging where random trees are constructed from\n",
        "# samples of the training dataset. You can construct an Extra Trees model for classi\fcation using\n",
        "# the ExtraTreesClassifier class3. The example below provides a demonstration of extra trees\n",
        "# with the number of trees set to 100 and splits chosen from 7 random features."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1co_iDqIOSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0d7e4a0-cc2e-4173-da3c-2dcaa1fc4f08"
      },
      "source": [
        "# Extra Trees Classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "num_trees = 100\n",
        "max_features = 7\n",
        "kfold = KFold(n_splits=10, random_state=7)\n",
        "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7759227614490773\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}